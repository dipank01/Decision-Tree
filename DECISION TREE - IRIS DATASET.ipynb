{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate entropy\n",
    "def Entropy(y):\n",
    "    d = {}\n",
    "    for i in y:\n",
    "        if i in d:\n",
    "            d[i] += 1\n",
    "        else:\n",
    "            d[i] = 1\n",
    "    \n",
    "    total = len(y)\n",
    "    entropy = 0\n",
    "    for ele in d:\n",
    "        entropy += (-d[ele]/total)*(np.log2(d[ele]/total))\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate gain of a function\n",
    "def gain(data,s_feature,target_feature):       \n",
    "        n_entropy = 0\n",
    "        vals,counts= np.unique(data[s_feature],return_counts=True)\n",
    "        for i in range(len(vals)):\n",
    "            k=Entropy(data.where(data[s_feature]==vals[i]).dropna()[target_feature])\n",
    "            n_entropy += (counts[i]/np.sum(counts))*k\n",
    "        return n_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate information gain\n",
    "def Infogain(df,s_feature,y):\n",
    "    total_entropy = Entropy(df[y])\n",
    "  \n",
    "    Information_Gain = total_entropy - gain(df,s_feature,y)\n",
    "    \n",
    "    return Information_Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate split info\n",
    "def split_info(data,f):\n",
    "    elements,counts = np.unique(data[f],return_counts = True)\n",
    "    split=0\n",
    "    for i in range(len(elements)):\n",
    "        split += (-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts))\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate gain ratio\n",
    "def Gain_ratio(info_gain,data,best_feature):\n",
    "    ratio =  info_gain/split_info(data,best_feature)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function to implement tree in given structure\n",
    "def DecisionTree(data,originaldata,features,target_feature=\"target\",parent = None,level=0): \n",
    "    \n",
    "    # Base case 1 - case where we have reached the leaf node\n",
    "    if (len(np.unique(data[target_feature])) <= 1):   \n",
    "        \n",
    "        elements,counts = np.unique(data[target_feature],return_counts = True)\n",
    "        print('Level ',level)\n",
    "        if elements ==0 :\n",
    "            print('Count of 0 =',np.sum(counts))\n",
    "        elif elements ==1 :\n",
    "            print('Count of 1 =',np.sum(counts))\n",
    "        elif elements ==2 :\n",
    "            print('Count of 2 =',np.sum(counts))\n",
    "        print('Current Entropy is =',Entropy(data[target_feature]))\n",
    "        print('Reached Leaf Node ')\n",
    "        print()\n",
    "        return np.unique(data[target_feature])[0]\n",
    "    \n",
    "    #elif len(data) == 0:                                           # checking the data is empty or not\n",
    "       \n",
    "    #    return np.unique(orignaldata[target_feature])\n",
    "    \n",
    "    # Base case 2 - case where no features are left to split upon\n",
    "    elif len(features) == 0 :\n",
    "        return parent\n",
    "    \n",
    "    else :\n",
    "\n",
    "        P_node = np.unique(data[target_feature])                    # add all the unique values of target in parent node\n",
    "        \n",
    "        values = []\n",
    "        for feature in features :                                   # loop over all the unused features\n",
    "            v = Infogain(data,feature,target_feature)               # getting a list of information gain of all the features\n",
    "            values.append(v)\n",
    "        \n",
    "        best_feature_index = np.argmax(values)                      # selecting best feature based on max info gain\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        #tree = {best_feature:{}}            \n",
    "        \n",
    "        total_entropy = Entropy(data[target_feature])               # entropy of current node\n",
    "       \n",
    "        \n",
    "        ratio=Gain_ratio(max(values),data,best_feature)             # gain ratio of the feature on which we split up on\n",
    "        \n",
    "        #Printing the tree\n",
    "        \n",
    "        elements,counts = np.unique(data[target_feature],return_counts = True)\n",
    "        print('Level ',level)                               \n",
    "        for i in range(len(elements)):\n",
    "            if elements[i]==0 :\n",
    "                print('count of 0  =',counts[i])\n",
    "            elif elements[i]==1 :\n",
    "                print('count of 1  =',counts[i])\n",
    "            elif elements[i]==2 :\n",
    "                print('count of 2  =',counts[i])\n",
    "      \n",
    "        print('Current entropy is   = ',total_entropy)  \n",
    "        print('Splitting on feature ',best_feature,' with gain ratio ', ratio)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        \n",
    "        new_features = features                                      # removing the function used to split      \n",
    "        features=[]\n",
    "        for i in new_features :                     \n",
    "                                                   \n",
    "            if i != best_feature :                  \n",
    "                features.append(i)\n",
    "        level += 1       \n",
    "        new_features=None                         \n",
    "        \n",
    "        for vals in np.unique(data[best_feature]):   \n",
    "            \n",
    "            value = vals\n",
    "            sub_data = (data[data[best_feature] == value]).dropna()\n",
    "            \n",
    "            subtree = DT(sub_data,data,features,target_feature,P_node,level)\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sl_labeled', 'sw_labeled', 'pl_labeled', 'pw_labeled'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import datasets                                             # importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()                                              # loading iris dataset\n",
    "\n",
    "df = pd.DataFrame(iris.data)\n",
    "df.columns = [\"sl\", \"sw\", 'pl', 'pw']\n",
    "y = pd.DataFrame(iris.target)\n",
    "y.columns = ['target']\n",
    "\n",
    "\n",
    "def label(val, *boundaries):                                             # labeling the data\n",
    "    if (val < boundaries[0]):\n",
    "        return 'a'\n",
    "    elif (val < boundaries[1]):\n",
    "        return 'b'\n",
    "    elif (val < boundaries[2]):\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'd'\n",
    "\n",
    "#Function to convert a continuous data into labelled data\n",
    "#There are 4 lables  - a, b, c, d\n",
    "def toLabel(df, old_feature_name):\n",
    "    second = df[old_feature_name].mean()\n",
    "    minimum = df[old_feature_name].min()\n",
    "    first = (minimum + second)/2\n",
    "    maximum = df[old_feature_name].max()\n",
    "    third = (maximum + second)/2\n",
    "    return df[old_feature_name].apply(label, args= (first, second, third))\n",
    "\n",
    "#Convert all columns to labelled data\n",
    "df['sl_labeled'] = toLabel(df, 'sl')\n",
    "df['sw_labeled'] = toLabel(df, 'sw')\n",
    "df['pl_labeled'] = toLabel(df, 'pl')\n",
    "df['pw_labeled'] = toLabel(df, 'pw')\n",
    "\n",
    "df.head()\n",
    "df.drop(['sl', 'sw', 'pl', 'pw'], axis = 1, inplace = True)    \n",
    "df['target']=y                                                    # Adding the target column in dataset\n",
    "print(df.columns[:-1])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level  0\n",
      "count of 0  = 50\n",
      "count of 1  = 50\n",
      "count of 2  = 50\n",
      "Current entropy is   =  1.584962500721156\n",
      "Splitting on feature  pw_labeled  with gain ratio  0.6996382036222091\n",
      "\n",
      "Level  1\n",
      "Count of 0 = 50\n",
      "Current Entropy is = 0.0\n",
      "Reached Leaf Node \n",
      "\n",
      "Level  1\n",
      "Count of 1 = 10\n",
      "Current Entropy is = 0.0\n",
      "Reached Leaf Node \n",
      "\n",
      "Level  1\n",
      "count of 1  = 40\n",
      "count of 2  = 16\n",
      "Current entropy is   =  0.863120568566631\n",
      "Splitting on feature  pl_labeled  with gain ratio  0.4334099495621067\n",
      "\n",
      "Level  2\n",
      "Count of 1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached Leaf Node \n",
      "\n",
      "Level  2\n",
      "count of 1  = 39\n",
      "count of 2  = 8\n",
      "Current entropy is   =  0.6581912658132185\n",
      "Splitting on feature  sl_labeled  with gain ratio  0.12674503775809332\n",
      "\n",
      "Level  3\n",
      "Count of 2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached Leaf Node \n",
      "\n",
      "Level  3\n",
      "Count of 1 = 14\n",
      "Current Entropy is = 0.0\n",
      "Reached Leaf Node \n",
      "\n",
      "Level  3\n",
      "count of 1  = 23\n",
      "count of 2  = 7\n",
      "Current entropy is   =  0.783776947484701\n",
      "Splitting on feature  sw_labeled  with gain ratio  0.07092036405148876\n",
      "\n",
      "Level  4\n",
      "Count of 1 = 6\n",
      "Current Entropy is = 0.0\n",
      "Reached Leaf Node \n",
      "\n",
      "Level  3\n",
      "Count of 1 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached Leaf Node \n",
      "\n",
      "Level  2\n",
      "Count of 2 = 8\n",
      "Current Entropy is = 0.0\n",
      "Reached Leaf Node \n",
      "\n",
      "Level  1\n",
      "Count of 2 = 34\n",
      "Current Entropy is = 0.0\n",
      "Reached Leaf Node \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree=DecisionTree(df, df, df.columns[:-1])     # printing steps\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
